{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sajjat-Hossain/ML_Project/blob/main/Heart_Failure_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTChZPXN98-Y"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/heart.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# Encoding categorical variables\n",
        "categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = data_encoded.drop(columns=['HeartDisease'])\n",
        "y = data_encoded['HeartDisease']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression(random_state=42)\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = logistic_model.predict(X_test_scaled)\n",
        "y_prob_lr = logistic_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Random Forest\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest_model.predict(X_test)\n",
        "y_prob_rf = random_forest_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Feature Importances\n",
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': random_forest_model.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Data distribution for numerical features\n",
        "numerical_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.histplot(data[feature], kde=True, color='blue')\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 1. Distribution of Target Variable\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=data, x='HeartDisease', palette='coolwarm')\n",
        "plt.title(\"Distribution of Target Variable (Heart Disease)\")\n",
        "plt.xlabel(\"Heart Disease (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Correlation Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(data_encoded.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap of Features\")\n",
        "plt.show()\n",
        "\n",
        "# 3. ROC Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic Regression (AUC = {roc_auc_lr:.2f})\")\n",
        "\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {roc_auc_rf:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Precision-Recall Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_prob_lr)\n",
        "plt.plot(recall_lr, precision_lr, label=\"Logistic Regression\")\n",
        "\n",
        "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_prob_rf)\n",
        "plt.plot(recall_rf, precision_rf, label=\"Random Forest\")\n",
        "\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 5. Extended Feature Importance (Random Forest)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=feature_importances, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n",
        "\n",
        "# Metrics for comparison\n",
        "metrics = {\n",
        "    \"Accuracy\": [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_rf)],\n",
        "    \"Precision\": [precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_rf)],\n",
        "    \"Recall\": [recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_rf)],\n",
        "    \"F1 Score\": [f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_rf)],\n",
        "    \"ROC AUC\": [roc_auc_score(y_test, y_prob_lr), roc_auc_score(y_test, y_prob_rf)]\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics, index=[\"Logistic Regression\", \"Random Forest\"])\n",
        "metrics_df.plot(kind='bar', figsize=(12, 6), colormap='coolwarm', edgecolor='black')\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrices\n",
        "print(\"\\nConfusion Matrices:\")\n",
        "print(\"Logistic Regression:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(\"\\nRandom Forest:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "# Classification Reports\n",
        "print(\"\\nClassification Report (Logistic Regression):\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"\\nClassification Report (Random Forest):\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# User Input and Prediction\n",
        "def get_user_input():\n",
        "    print(\"\\nProvide the following details for prediction:\")\n",
        "    input_data = {\n",
        "        'Age': float(input(\"Age: \")),\n",
        "        'RestingBP': float(input(\"Resting Blood Pressure (mmHg): \")),\n",
        "        'Cholesterol': float(input(\"Cholesterol (mg/dL): \")),\n",
        "        'FastingBS': int(input(\"Fasting Blood Sugar (>120 mg/dL, 1/0): \")),\n",
        "        'MaxHR': float(input(\"Maximum Heart Rate Achieved: \")),\n",
        "        'Oldpeak': float(input(\"ST Depression Induced by Exercise (Float Data): \")),\n",
        "        'Sex_M': int(input(\"Sex (Male=1, Female=0): \")),\n",
        "        'ChestPainType_ATA': int(input(\"Chest Pain Type (ATA=1, else=0): \")),\n",
        "        'ChestPainType_NAP': int(input(\"Chest Pain Type (NAP=1, else=0): \")),\n",
        "        'ChestPainType_TA': int(input(\"Chest Pain Type (TA=1, else=0): \")),\n",
        "        'RestingECG_Normal': int(input(\"Resting ECG (Normal=1, else=0): \")),\n",
        "        'RestingECG_ST': int(input(\"Resting ECG (ST=1, else=0): \")),\n",
        "        'ExerciseAngina_Y': int(input(\"Exercise-Induced Angina (Yes=1, No=0): \")),\n",
        "        'ST_Slope_Flat': int(input(\"ST Slope (Flat=1, else=0): \")),\n",
        "        'ST_Slope_Up': int(input(\"ST Slope (Up=1, else=0): \"))\n",
        "    }\n",
        "    return pd.DataFrame([input_data])\n",
        "\n",
        "user_input = get_user_input()\n",
        "user_input = user_input.reindex(columns=X.columns, fill_value=0)\n",
        "user_input_scaled = scaler.transform(user_input)\n",
        "\n",
        "lr_prediction = logistic_model.predict(user_input_scaled)\n",
        "rf_prediction = random_forest_model.predict(user_input)\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(f\"Logistic Regression Prediction (Heart Disease: 1/0): {lr_prediction[0]}\")\n",
        "print(f\"Random Forest Prediction (Heart Disease: 1/0): {rf_prediction[0]}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xZCXpYmeNx4YyjePorLcHO3JTP8Khj6S",
      "authorship_tag": "ABX9TyNSIwVEmopwChmY30KN67V1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}